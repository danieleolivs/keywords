# -*- coding: utf-8 -*-
"""Untitled

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pw8-UBzhacL_3T_qyAY377uyAMSa-wP9
"""

import csv
import re
import json
import sys
from google.colab import files

def extrair_frases_curtas(ementa_texto):
    if not isinstance(ementa_texto, str):
        return []

    ementa_limpa = ' '.join(ementa_texto.strip().split())
    partes = re.split(r'\s*[\.-]\s*', ementa_limpa)

    frases_validas = []

    for parte in partes:
        frase = parte.strip()
        if not frase:
            continue

        if frase[0] in {',', '"', "'"} or frase[-1] in {',', '"', "'"}:
            continue

        palavras = frase.split()
        if 2 <= len(palavras) <= 7:
            frase_sem_marcador = re.sub(r'^[0-9a-zA-Z][\.\)]\s*', '', frase).strip()

            if not frase_sem_marcador:
                continue

            palavras_validas = [p for p in frase_sem_marcador.split() if len(p) > 2]
            if len(palavras_validas) < len(frase_sem_marcador.split()) / 2:
                continue

            padrao_fragmentos = re.compile(r'\b(deveras|sendo assim|como|se|com|e|é|ou|não|para|por|como|como litisconsorte|com ressalvas|s)\b', re.I)
            if padrao_fragmentos.search(frase_sem_marcador) and len(frase_sem_marcador.split()) <= 5:
                continue

            if re.search(r'\d', frase_sem_marcador) and not re.search(r'\bICMS\b', frase_sem_marcador):
                continue

            if frase_sem_marcador.count(',') > 1 or '(' in frase_sem_marcador or ')' in frase_sem_marcador:
                continue

            frases_validas.append(frase_sem_marcador)

    frases_unicas = list(dict.fromkeys(frases_validas))  # Remove duplicatas mantendo ordem

    return frases_unicas

uploaded = files.upload()
csv_input_path = next(iter(uploaded))
resultados = {}

try:
    with open(csv_input_path, mode='r', encoding='utf-8-sig') as csvfile:
        reader = csv.DictReader(csvfile)
        if 'ementa' not in reader.fieldnames or 'id' not in reader.fieldnames:
            print(f"Erro: Colunas 'id' ou 'ementa' não encontradas no CSV.", file=sys.stderr)
            sys.exit(1)

        print(f"Processando arquivo: {csv_input_path}")
        count = 0
        for i, row in enumerate(reader):
            ementa = row.get('ementa', '')
            row_id = row.get('id', f'linha_{i+2}')

            if ementa:
                frases_extraidas = extrair_frases_curtas(ementa)
                if frases_extraidas:
                    resultados[row_id] = frases_extraidas
                    count += 1

        print(f"Processadas {i+1} linhas. Encontradas ementas com frases curtas em {count} registros.")

except FileNotFoundError:
    print(f"Erro: Arquivo CSV não encontrado em {csv_input_path}", file=sys.stderr)
    sys.exit(1)
    resultados = {}
    try:
        with open(csv_input_path, mode='r', encoding='latin-1') as csvfile:
            reader = csv.DictReader(csvfile)
            if 'ementa' not in reader.fieldnames or 'id' not in reader.fieldnames:
                print(f"Erro: Colunas 'id' ou 'ementa' não encontradas no CSV (tentativa latin-1).", file=sys.stderr)
                sys.exit(1)

            print(f"Processando arquivo: {csv_input_path} (Latin-1)")
            count = 0
            for i, row in enumerate(reader):
                ementa = row.get('ementa', '')
                row_id = row.get('id', f'linha_{i+2}')

                if ementa:
                    frases_extraidas = extrair_frases_curtas(ementa)
                    if frases_extraidas:
                        resultados[row_id] = frases_extraidas
                        count += 1
            print(f"Processadas {i+1} linhas. Encontradas ementas com frases curtas em {count} registros.")

    except Exception as e_fallback:
        print(f"Erro ao processar o arquivo CSV com latin-1: {e_fallback}", file=sys.stderr)
        sys.exit(1)
except Exception as e:
    print(f"Erro inesperado ao processar o arquivo CSV: {e}", file=sys.stderr)
    sys.exit(1)

json_output_path = "frases_extraidas.json"

with open(json_output_path, 'w', encoding='utf-8') as jsonfile:
    json.dump(resultados, jsonfile, ensure_ascii=False, indent=2)

files.download(json_output_path)